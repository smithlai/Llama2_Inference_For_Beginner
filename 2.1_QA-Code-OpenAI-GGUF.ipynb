{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a734497c-6379-4d65-a468-e3921f04fe13",
   "metadata": {},
   "source": [
    "# Deeplake on GPT and GGUF\n",
    "https://python.langchain.com/docs/use_cases/question_answering/how_to/code/code-analysis-deeplake\n",
    "\n",
    "This notebook demostrate the difference between ChatGPT and Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccb3017-73c1-4910-b51e-33cb38b6ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai\n",
    "# !pip3 install openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724aa62-5f7c-4b36-9975-32d8cf484a71",
   "metadata": {},
   "source": [
    "## OpenAI (GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff8b9da-acd8-435a-93b0-a0451687dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,dotenv_values\n",
    "import os\n",
    "\n",
    "# load_dotenv()\n",
    "# openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKey')\n",
    "# OR\n",
    "dotenv_cfg = dotenv_values(\".env\")\n",
    "openai_api_key=dotenv_cfg.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85686f24-f19a-490b-ae00-40f1540a6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= OpenAI Transformer==========\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "gpt_embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "#**Note**: This will print your openai apikey\n",
    "# gpt_embeddings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fd1295-24f5-4394-93cf-3ade8f9d53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= OpenAI Model==========\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=openai_api_key,model_name=\"gpt-3.5-turbo-0613\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653154b5-0b93-4e79-8b1e-adcf02662f9e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154fde9b-bbae-4828-9602-e1ec560e94fd",
   "metadata": {},
   "source": [
    "### Load text into Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e126b4b3-83a8-4136-a80e-73701e61a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'mydata/langchain-sourcecode' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/langchain-ai/langchain.git mydata/langchain-sourcecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cc83ff-976e-4823-af7c-0c303c120fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"mydata/langchain-sourcecode/libs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8bbdf3-40b6-4ab9-b21e-dae545f462c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 5018 docs from 3385 *.py\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "docs = []\n",
    "files = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".py\") and \"*venv/\" not in dirpath:\n",
    "            try:\n",
    "                filepath=os.path.join(dirpath, file)\n",
    "                loader = TextLoader(filepath, encoding=\"utf-8\")\n",
    "                files.append(filepath)\n",
    "                docs.extend(loader.load_and_split())\n",
    "            except Exception as e:\n",
    "                pass\n",
    "print(f\"load {len(docs)} docs from {len(files)} *.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64718247-92b8-44d2-94f6-c4d949618040",
   "metadata": {},
   "source": [
    "### Split Documants\n",
    "#### CharacterTextSplitter VS RecursiveCharacterTextSplitter\n",
    "##### RecursiveCharacterTextSplitter\n",
    "> https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter\n",
    "> tries to split on them in order until the chunks are small enough. The default list is \\[\"\\n\\n\", \"\\n\", \" \", \"\"\\]\n",
    "\n",
    "##### CharacterTextSplitter\n",
    "> https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/character_text_splitter\n",
    "> This is the simplest method. This splits based on characters (by default \"\\n\\n\") and measure chunk length by number of characters.\n",
    ">\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3adb2c0c-a7ed-475b-966f-16df1319f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8285 documents after split\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "print(f\"There are {len(split_docs)} documents after split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a232769-6188-4d61-a3c6-6d94181b0bad",
   "metadata": {},
   "source": [
    "### Make Vectorstore with deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c3b581-39a6-48cd-8506-fc4ee299a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9907fa-f980-4413-b92d-4a506ed69800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data locally\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/activeloop_deeplake#deep-lake-locally\n",
    "def make_local_vectorstore(split_docs,embeddings, dataset_path=\"./.my_deeplake/\", overwrite=False):\n",
    "    from langchain.vectorstores import DeepLake\n",
    "    from os import path\n",
    "    if overwrite or not path.exists(dataset_path):\n",
    "        local_vectorstore=DeepLake.from_documents(split_docs, dataset_path=dataset_path, embedding=embeddings, overwrite=True)\n",
    "    else:\n",
    "        local_vectorstore=DeepLake(dataset_path=dataset_path, embedding=embeddings, read_only=True)\n",
    "    return local_vectorstore \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533e9384-8474-4d10-ace7-835d3ace47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data on activeloop hub\n",
    "def make_hub_vectorstore(split_docs,embedding, hub_name, overwrite=False):\n",
    "    from langchain.vectorstores import DeepLake    \n",
    "    os.environ['ACTIVELOOP_TOKEN'] = dotenv_cfg.get('ACTIVELOOP_TOKEN')\n",
    "    dataset_path=f\"hub://{dotenv_cfg.get('ACTIVELOOP_TOKEN')}/{ACTIVELOOP_USER}\"\n",
    "    if overwrite:\n",
    "        hub_vectorstore = DeepLake.from_documents(\n",
    "            split_docs, embeddings, dataset_path=dataset_path, runtime={\"tensor_db\": True} #, overwrite=True\n",
    "        )\n",
    "    else:\n",
    "        hub_vectorstore = DeepLake(dataset_path=dataset_path, embedding=embeddings, readonly=True)\n",
    "    return hub_vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5057d9ea-d730-47ae-8666-0b35bfe22b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in ./.my_gpt_deeplake/ already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# gpt_vectorstore = make_hub_vectorstore(split_docs, gpt_embeddings,hub_name=\"my_gpt_deeplake\")\n",
    "gpt_vectorstore = make_local_vectorstore(split_docs, gpt_embeddings, dataset_path=\"./.my_gpt_deeplake/\", overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c61bf-1dcd-4376-81ce-5a0e73011c74",
   "metadata": {},
   "source": [
    "# Inference test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287fc4a1-30b0-4ec4-b25a-ab93c35302d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our inference test function\n",
    "from timeit import default_timer as timer\n",
    "def inferenceQA(chat_model, vectorstore, questions):\n",
    "    qa = ConversationalRetrievalChain.from_llm(chat_model, retriever=vectorstore.as_retriever())\n",
    "    chat_history = []\n",
    "    qa_dict = {}\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"-> **Question**: {question} \\n\")\n",
    "        start=timer()\n",
    "        result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "        end=timer()\n",
    "        print(f\"**{int((end-start)*100)/100.0} secs**\\n\")\n",
    "        print(f\"**Answer**: {result['answer']} \\n\")\n",
    "        chat_history.append((question, result[\"answer\"]))\n",
    "        qa_dict[question] = result[\"answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a2b9c1-57f3-4a6b-9e4c-c2baa46fc00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What is the class hierarchy? \n",
      "\n",
      "**4.32 secs**\n",
      "\n",
      "**Answer**: The class hierarchy in the code includes the following classes:\n",
      "\n",
      "- BaseMemory\n",
      "  - BaseChatMemory\n",
      "    - <name>Memory (e.g., ZepMemory, MotorheadMemory)\n",
      "\n",
      "- BaseChatMessageHistory\n",
      "  - <name>ChatMessageHistory (e.g., ZepChatMessageHistory)\n",
      "\n",
      "These classes are part of the langchain_core module. \n",
      "\n",
      "-> **Question**: What classes are derived from the Chain class? \n",
      "\n",
      "**24.87 secs**\n",
      "\n",
      "**Answer**: The following classes are derived from the Chain class:\n",
      "\n",
      "1. APIChain (from langchain.chains.api.base)\n",
      "2. OpenAPIEndpointChain (from langchain.chains.api.openapi.chain)\n",
      "3. AnalyzeDocumentChain (from langchain.chains.combine_documents.base)\n",
      "4. MapReduceDocumentsChain (from langchain.chains.combine_documents.map_reduce)\n",
      "5. MapRerankDocumentsChain (from langchain.chains.combine_documents.map_rerank)\n",
      "6. ReduceDocumentsChain (from langchain.chains.combine_documents.reduce)\n",
      "7. RefineDocumentsChain (from langchain.chains.combine_documents.refine)\n",
      "8. StuffDocumentsChain (from langchain.chains.combine_documents.stuff)\n",
      "9. ConstitutionalChain (from langchain.chains.constitutional_ai.base)\n",
      "10. ConversationChain (from langchain.chains.conversation.base)\n",
      "11. ChatVectorDBChain (from langchain.chains.conversational_retrieval.base)\n",
      "12. ConversationalRetrievalChain (from langchain.chains.conversational_retrieval.base)\n",
      "13. FlareChain (from langchain.chains.flare.base)\n",
      "14. ArangoGraphQAChain (from langchain.chains.graph_qa.arangodb)\n",
      "15. GraphQAChain (from langchain.chains.graph_qa.base)\n",
      "16. GraphCypherQAChain (from langchain.chains.graph_qa.cypher)\n",
      "17. FalkorDBQAChain (from langchain.chains.graph_qa.falkordb)\n",
      "18. HugeGraphQAChain (from langchain.chains.graph_qa.hugegraph)\n",
      "19. KuzuQAChain (from langchain.chains.graph_qa.kuzu)\n",
      "20. NebulaGraphQAChain (from langchain.chains.graph_qa.nebulagraph)\n",
      "21. NeptuneOpenCypherQAChain (from langchain.chains.graph_qa.neptune_cypher)\n",
      "22. GraphSparqlQAChain (from langchain.chains.graph_qa.sparql)\n",
      "23. HypotheticalDocumentEmbedder (from langchain.chains.hyde.base)\n",
      "24. LLMChain (from langchain.chains.llm)\n",
      "25. LLMCheckerChain (from langchain.chains.llm_checker.base)\n",
      "26. LLMMathChain (from langchain.chains.llm_math.base)\n",
      "27. LLMRequestsChain (from langchain.chains.llm_requests)\n",
      "28. LLMSummarizationCheckerChain (from langchain.chains.llm_summarization_checker.base)\n",
      "29. OpenAIModerationChain (from langchain.chains.moderation)\n",
      "30. NatBotChain (from langchain.chains.natbot.base)\n",
      "31. QAGenerationChain (from langchain.chains.qa_generation.base)\n",
      "32. QAWithSourcesChain (from langchain.chains.qa_with_sources.base)\n",
      "33. RetrievalQAWithSourcesChain (from langchain.chains.qa_with_sources.retrieval)\n",
      "34. VectorDBQAWithSourcesChain (from langchain.chains.qa_with_sources.vector_db)\n",
      "35. RetrievalQA (from langchain.chains.retrieval_qa.base)\n",
      "36. VectorDBQA (from langchain.chains.retrieval_qa.base)\n",
      "37. LLMRouterChain (from langchain.chains.router)\n",
      "38. MultiPromptChain (from langchain.chains.router)\n",
      "39. MultiRetrievalQAChain (from langchain.chains.router)\n",
      "40. MultiRouteChain (from langchain.chains.router)\n",
      "41. RouterChain (from langchain.chains.router)\n",
      "42. SequentialChain (from langchain.chains.sequential)\n",
      "43. SimpleSequentialChain (from langchain.chains.sequential)\n",
      "44. TransformChain (from langchain.chains.transform)\n",
      "\n",
      "Note: This list may not be exhaustive and there may be additional classes derived from the Chain class that are not included here. \n",
      "\n",
      "-> **Question**: What kind of retrievers does LangChain have? \n",
      "\n",
      "**15.0 secs**\n",
      "\n",
      "**Answer**: The classes derived from the `Chain` class in LangChain include:\n",
      "\n",
      "1. `APIChain`\n",
      "2. `OpenAPIEndpointChain`\n",
      "3. `AnalyzeDocumentChain`\n",
      "4. `MapReduceDocumentsChain`\n",
      "5. `MapRerankDocumentsChain`\n",
      "6. `ReduceDocumentsChain`\n",
      "7. `RefineDocumentsChain`\n",
      "8. `StuffDocumentsChain`\n",
      "9. `ConstitutionalChain`\n",
      "10. `ConversationChain`\n",
      "11. `ChatVectorDBChain`\n",
      "12. `ConversationalRetrievalChain`\n",
      "13. `FlareChain`\n",
      "14. `ArangoGraphQAChain`\n",
      "15. `GraphQAChain`\n",
      "16. `GraphCypherQAChain`\n",
      "17. `FalkorDBQAChain`\n",
      "18. `HugeGraphQAChain`\n",
      "19. `KuzuQAChain`\n",
      "20. `NebulaGraphQAChain`\n",
      "21. `NeptuneOpenCypherQAChain`\n",
      "22. `GraphSparqlQAChain`\n",
      "23. `HypotheticalDocumentEmbedder`\n",
      "24. `LLMChain`\n",
      "25. `LLMCheckerChain`\n",
      "26. `LLMMathChain`\n",
      "27. `LLMRequestsChain`\n",
      "28. `LLMSummarizationCheckerChain`\n",
      "29. `OpenAIModerationChain`\n",
      "30. `NatBotChain`\n",
      "31. `QAGenerationChain`\n",
      "32. `QAWithSourcesChain`\n",
      "33. `RetrievalQAWithSourcesChain`\n",
      "34. `VectorDBQAWithSourcesChain`\n",
      "35. `RetrievalQA`\n",
      "36. `VectorDBQA`\n",
      "37. `LLMRouterChain`\n",
      "38. `MultiPromptChain`\n",
      "39. `MultiRetrievalQAChain`\n",
      "40. `MultiRouteChain`\n",
      "41. `RouterChain`\n",
      "42. `SequentialChain`\n",
      "43. `SimpleSequentialChain`\n",
      "44. `TransformChain`\n",
      "\n",
      "Please note that this list may not be exhaustive, and there might be additional classes derived from the `Chain` class in LangChain. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inferenceQA(chat_model, gpt_vectorstore, questions = [\n",
    "        \"What is the class hierarchy?\",\n",
    "        \"What classes are derived from the Chain class?\",\n",
    "        \"What kind of retrievers does LangChain have?\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a0ad6-7fec-445b-ba64-73b741164920",
   "metadata": {},
   "source": [
    "## Llama2 (GGUF on CTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9261b89-d521-4660-88c8-bc09dab66497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== GGUF =========\n",
    "from langchain.llms import CTransformers\n",
    "import os\n",
    "\n",
    "model_id=os.path.abspath('./models/Llama-2-7b-Chat-GGUF')\n",
    "\n",
    "# context_length must be > chunk_size=1000 of text_splitter\n",
    "# If context length is too short, the output would be poor.\n",
    "config = {'max_new_tokens': 2048, 'repetition_penalty': 1.05,'context_length':4096}\n",
    "# https://api.python.langchain.com/en/latest/llms/langchain.llms.ctransformers.CTransformers.html\n",
    "cTransformers_llm = CTransformers(model=model_id, model_file=\"llama-2-7b-chat.Q4_K_M.gguf\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa992969-c928-4fee-84d5-31424c93df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding data\n",
    "from mylib.MyModelUtils import MyModelUtils\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "llama2_embeddings=HuggingFaceEmbeddings(\n",
    "    model_name=os.path.abspath(\"./models/sentence-transformers/all-mpnet-base-v2\"), \n",
    "    model_kwargs={\"device\": MyModelUtils.device()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9314bf3d-eee5-4311-a64d-a2bcc6323294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 8285 embeddings in 17 batches of size 500:: 100% 17/17 [03:43<00:00, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='./.my_llama2_deeplake/', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (8285, 1)     str     None   \n",
      " metadata     json      (8285, 1)     str     None   \n",
      " embedding  embedding  (8285, 768)  float32   None   \n",
      "    id        text      (8285, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# llama2_vectorstore = make_hub_vectorstore(split_docs, llama2_embeddings,hub_name=\"my_llama2_deeplake\")\n",
    "llama2_vectorstore = make_local_vectorstore(split_docs, llama2_embeddings, dataset_path=\"./.my_llama2_deeplake/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "745aab7f-dd44-41d0-af57-f85e734b5eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What is the class hierarchy? \n",
      "\n",
      "**208.2 secs**\n",
      "\n",
      "**Answer**:  The class hierarchy for the given code is as follows:\n",
      "\n",
      "* `BaseTool`: The base class for all tools.\n",
      "* `AmadeusBaseTool`: An abstract class that implements the `BaseTool` class.\n",
      "* `BaseBrowserTool`: An abstract class that implements the `BaseTool` class.\n",
      "* `GmailBaseTool`: An abstract class that implements the `BaseTool` class.\n",
      "* `O365BaseTool`: An abstract class that implements the `BaseTool` class.\n",
      "* `SlackBaseTool`: An abstract class that implements the `BaseTool` class.\n",
      "* `Embeddings`: A class that inherits from `BaseTool`.\n",
      "* `BaseMemory`: A class that inherits from `BaseTool`.\n",
      "* `BaseChatMemory`: A class that inherits from `BaseMemory`.\n",
      "* `ZepMemory`: A class that inherits from `BaseChatMemory`.\n",
      "* `MotorheadMemory`: A class that inherits from `BaseChatMemory`.\n",
      "* `BaseChatMessageHistory`: A class that inherits from `BaseTool`.\n",
      "* `<name>ChatMessageHistory`: A class that inherits from `BaseChatMessageHistory`.\n",
      "\n",
      "The hierarchy shows the relationships between the classes and how they inherit from each other. \n",
      "\n",
      "-> **Question**: What classes are derived from the Chain class? \n",
      "\n",
      "**142.94 secs**\n",
      "\n",
      "**Answer**:  The Chain class is derived from the following classes:\n",
      "\n",
      "* LLMChain\n",
      "* MapReduceChain\n",
      "* RouterChain \n",
      "\n",
      "-> **Question**: What kind of retrievers does LangChain have? \n",
      "\n",
      "**144.11 secs**\n",
      "\n",
      "**Answer**:  The __init__ method in LangChain inherits from BaseCallbackHandler. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inferenceQA(cTransformers_llm, llama2_vectorstore, questions = [\n",
    "        \"What is the class hierarchy?\",\n",
    "        \"What classes are derived from the Chain class?\",\n",
    "        \"What kind of retrievers does LangChain have?\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773cf989-0c4e-4ade-bd3c-7114f7bb8774",
   "metadata": {},
   "source": [
    "# What will happen if we use GPT-embedding vector store on Lllama2, or vice versa?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670fae3-2bb1-4caa-ac6a-04f05d1a5aca",
   "metadata": {},
   "source": [
    "**Conclusion**: \n",
    "vectorstore do affect to chat model result. And **vertorstore is more important than Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eedb51d-6e63-43e5-b954-4da5da03040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What is the class hierarchy? \n",
      "\n",
      "**3.05 secs**\n",
      "\n",
      "**Answer**: The class hierarchy includes the following structures:\n",
      "\n",
      "- BaseTool\n",
      "- AmadeusBaseTool\n",
      "- BaseBrowserTool\n",
      "- GmailBaseTool\n",
      "- O365BaseTool\n",
      "- SlackBaseTool\n",
      "\n",
      "Additionally, there are other class hierarchies mentioned:\n",
      "\n",
      "- Embeddings --> <name>Embeddings\n",
      "- BaseMemory --> BaseChatMemory --> <name>Memory\n",
      "- BaseChatMessageHistory --> <name>ChatMessageHistory \n",
      "\n",
      "-> **Question**: What classes are derived from the Chain class? \n",
      "\n",
      "**2.65 secs**\n",
      "\n",
      "**Answer**: The specific classes derived from the Chain class are not mentioned in the provided context. \n",
      "\n",
      "-> **Question**: What kind of retrievers does LangChain have? \n",
      "\n",
      "**3.22 secs**\n",
      "\n",
      "**Answer**: LangChain has the following retrievers:\n",
      "\n",
      "1. MilvusRetriever\n",
      "2. WeaviateHybridSearchRetriever\n",
      "3. KayAiRetriever \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Llama2-embedding vertorstore on gpt\n",
    "inferenceQA(chat_model, llama2_vectorstore, questions = [\n",
    "        \"What is the class hierarchy?\",\n",
    "        \"What classes are derived from the Chain class?\",\n",
    "        \"What kind of retrievers does LangChain have?\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5deb63d6-5d93-4fd1-b4c7-d2ecd00f0c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What is the class hierarchy? \n",
      "\n",
      "**88.3 secs**\n",
      "\n",
      "**Answer**:  The class hierarchy for Memory is:\n",
      "BaseMemory --> BaseChatMemory --> <name>Memory (e.g. ZepMemory, MotorheadMemory)\n",
      "The class hierarchy for ChatMessageHistory is:\n",
      "BaseChatMessageHistory --> <name>ChatMessageHistory (e.g. ZepChatMessageHistory)\n",
      "The main helpers are:\n",
      "BaseChatMessageHistory\n",
      "BaseCacheMessageHistory\n",
      "BaseDocumentTransformer\n",
      "BaseOutputParser\n",
      "BasePromptTemplate\n",
      "BaseRetriever\n",
      "BaseStore\n",
      "\n",
      "Note: The answer is based on the provided context, if there is any change or updated answer, please let me know. \n",
      "\n",
      "-> **Question**: What classes are derived from the Chain class? \n",
      "\n",
      "**236.96 secs**\n",
      "\n",
      "**Answer**:   The Chain class is derived by many other classes, including:\n",
      "* APIChain\n",
      "* OpenAPIEndpointChain\n",
      "* AnalyzeDocumentChain\n",
      "* MapReduceDocumentsChain\n",
      "* MapRerankDocumentsChain\n",
      "* ReduceDocumentsChain\n",
      "* RefineDocumentsChain\n",
      "* StuffDocumentsChain\n",
      "* ConstitutionalChain\n",
      "* ConversationChain\n",
      "* ChatVectorDBChain\n",
      "* ConversationalRetrievalChain\n",
      "* FlareChain\n",
      "* ArangoGraphQAChain\n",
      "* GraphQAChain\n",
      "* GraphCypherQAChain\n",
      "* FalkorDBQAChain\n",
      "* HugeGraphQAChain\n",
      "* KuzuQAChain\n",
      "* NebulaGraphQAChain\n",
      "* NeptuneOpenCypherQAChain\n",
      "* GraphSparqlQAChain\n",
      "* HypotheticalDocumentEmbedder\n",
      "* LLMChain\n",
      "* LLMCheckerChain\n",
      "* LLMMathChain\n",
      "* LLMSummarizationCheckerChain\n",
      "* OpenAIModerationChain\n",
      "* NatBotChain\n",
      "* create_citation_fuzzy_match_chain\n",
      "\n",
      "* create_extraction_chain\n",
      "\n",
      "* create_extraction_chain_pydantic\n",
      "\n",
      "* create_qa_with_sources_chain\n",
      "\n",
      "* create_qa_with_structure_chain\n",
      "\n",
      "* create_tagging_chain\n",
      "\n",
      "* create_tagging_chain_pydantic\n",
      "\n",
      "* QAGenerationChain\n",
      "\n",
      "* QAWithSourcesChain\n",
      "\n",
      "* RetrievalQAChain\n",
      "\n",
      "* VectorDBQAChain\n",
      "\n",
      "* MultiPromptChain\n",
      "\n",
      "* MultiRetrievalQAChain\n",
      "\n",
      "* MultiRouteChain\n",
      "\n",
      "* LLMRouterChain\n",
      "\n",
      "\n",
      "You may not know the answer to this question, but it's important to understand that the Chain class is a base class that many other classes derive from, and these derived classes represent various use cases for chaining together LangChain components to perform complex natural language processing tasks. \n",
      "\n",
      "-> **Question**: What kind of retrievers does LangChain have? \n",
      "\n",
      "**313.33 secs**\n",
      "\n",
      "**Answer**:  LangChain has a wide variety of retrievers, including ones for popular platforms like Google Cloud, Azure, and Amazon Kendra, as well as specialized retrievers for specific use cases like multi-query, multi-vector, and time-weighted retrieval. Some retrievers are community-maintained and come from the LangChain community, while others are developed by the LangChain team. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gpt-embedding vertorstore on Llama2\n",
    "inferenceQA(cTransformers_llm, gpt_vectorstore, questions = [\n",
    "        \"What is the class hierarchy?\",\n",
    "        \"What classes are derived from the Chain class?\",\n",
    "        \"What kind of retrievers does LangChain have?\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376822a-099c-462c-9817-3a6a3579aac8",
   "metadata": {},
   "source": [
    "## Can we use FAISS to replace Deeplake?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b50ae-1346-4f80-9d77-0770658fd98b",
   "metadata": {},
   "source": [
    "**Conclusion**:\n",
    "FAISS and Deeplake are interchangable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e1cc311-ccc6-4822-885f-51b37539e67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What is the class hierarchy? \n",
      "\n",
      "**4.02 secs**\n",
      "\n",
      "**Answer**: The class hierarchy in the context provided is as follows:\n",
      "\n",
      "- BaseMemory\n",
      "  - BaseChatMemory\n",
      "    - \\<name\\>Memory (e.g., ZepMemory, MotorheadMemory)\n",
      "\n",
      "- BaseChatMessageHistory\n",
      "  - \\<name\\>ChatMessageHistory (e.g., ZepChatMessageHistory)\n",
      "\n",
      "Please note that \\<name\\> represents placeholder names and can be replaced with specific names like \"Zep\" or \"Motorhead\". \n",
      "\n",
      "-> **Question**: What classes are derived from the Chain class? \n",
      "\n",
      "**23.36 secs**\n",
      "\n",
      "**Answer**: The following classes are derived from the Chain class:\n",
      "\n",
      "1. APIChain (from langchain.chains.api.base)\n",
      "2. OpenAPIEndpointChain (from langchain.chains.api.openapi.chain)\n",
      "3. AnalyzeDocumentChain (from langchain.chains.combine_documents.base)\n",
      "4. MapReduceDocumentsChain (from langchain.chains.combine_documents.map_reduce)\n",
      "5. MapRerankDocumentsChain (from langchain.chains.combine_documents.map_rerank)\n",
      "6. ReduceDocumentsChain (from langchain.chains.combine_documents.reduce)\n",
      "7. RefineDocumentsChain (from langchain.chains.combine_documents.refine)\n",
      "8. StuffDocumentsChain (from langchain.chains.combine_documents.stuff)\n",
      "9. ConstitutionalChain (from langchain.chains.constitutional_ai.base)\n",
      "10. ConversationChain (from langchain.chains.conversation.base)\n",
      "11. ChatVectorDBChain (from langchain.chains.conversational_retrieval.base)\n",
      "12. ConversationalRetrievalChain (from langchain.chains.conversational_retrieval.base)\n",
      "13. FlareChain (from langchain.chains.flare.base)\n",
      "14. ArangoGraphQAChain (from langchain.chains.graph_qa.arangodb)\n",
      "15. GraphQAChain (from langchain.chains.graph_qa.base)\n",
      "16. GraphCypherQAChain (from langchain.chains.graph_qa.cypher)\n",
      "17. FalkorDBQAChain (from langchain.chains.graph_qa.falkordb)\n",
      "18. HugeGraphQAChain (from langchain.chains.graph_qa.hugegraph)\n",
      "19. KuzuQAChain (from langchain.chains.graph_qa.kuzu)\n",
      "20. NebulaGraphQAChain (from langchain.chains.graph_qa.nebulagraph)\n",
      "21. NeptuneOpenCypherQAChain (from langchain.chains.graph_qa.neptune_cypher)\n",
      "22. GraphSparqlQAChain (from langchain.chains.graph_qa.sparql)\n",
      "23. HypotheticalDocumentEmbedder (from langchain.chains.hyde.base)\n",
      "24. LLMChain (from langchain.chains.llm)\n",
      "25. LLMCheckerChain (from langchain.chains.llm_checker.base)\n",
      "26. LLMMathChain (from langchain.chains.llm_math.base)\n",
      "27. LLMRequestsChain (from langchain.chains.llm_requests)\n",
      "28. LLMSummarizationCheckerChain (from langchain.chains.llm_summarization_checker.base)\n",
      "29. MapReduceChain (from langchain.chains.mapreduce)\n",
      "30. OpenAIModerationChain (from langchain.chains.moderation)\n",
      "31. NatBotChain (from langchain.chains.natbot.base)\n",
      "32. QAGenerationChain (from langchain.chains.qa_generation.base)\n",
      "33. QAWithSourcesChain (from langchain.chains.qa_with_sources.base)\n",
      "34. RetrievalQAWithSourcesChain (from langchain.chains.qa_with_sources.retrieval)\n",
      "35. VectorDBQAWithSourcesChain (from langchain.chains.qa_with_sources.vector_db)\n",
      "36. RetrievalQA (from langchain.chains.retrieval_qa.base)\n",
      "37. VectorDBQA (from langchain.chains.retrieval_qa.base)\n",
      "38. LLMRouterChain (from langchain.chains.router)\n",
      "39. MultiPromptChain (from langchain.chains.router)\n",
      "40. MultiRetrievalQAChain (from langchain.chains.router)\n",
      "41. MultiRouteChain (from langchain.chains.router)\n",
      "42. RouterChain (from langchain.chains.router)\n",
      "43. SequentialChain (from langchain.chains.sequential)\n",
      "44. SimpleSequentialChain (from langchain.chains.sequential)\n",
      "45. TransformChain (from langchain.chains.transform)\n",
      "\n",
      "Note: This list may not be exhaustive as it only includes classes derived directly from the Chain class. There may be additional classes derived from these derived classes. \n",
      "\n",
      "-> **Question**: What kind of retrievers does LangChain have? \n",
      "\n",
      "**12.71 secs**\n",
      "\n",
      "**Answer**: LangChain has the following retrievers:\n",
      "\n",
      "1. ArceeRetriever\n",
      "2. ArxivRetriever\n",
      "3. AzureCognitiveSearchRetriever\n",
      "4. AmazonKnowledgeBasesRetriever\n",
      "5. BM25Retriever\n",
      "6. ChaindeskRetriever\n",
      "7. ChatGPTPluginRetriever\n",
      "8. CohereRagRetriever\n",
      "9. ContextualCompressionRetriever\n",
      "10. DocArrayRetriever\n",
      "11. ElasticSearchBM25Retriever\n",
      "12. EmbedchainRetriever\n",
      "13. EnsembleRetriever\n",
      "14. GoogleDocumentAIWarehouseRetriever\n",
      "15. GoogleCloudEnterpriseSearchRetriever\n",
      "16. GoogleVertexAIMultiTurnSearchRetriever\n",
      "17. GoogleVertexAISearchRetriever\n",
      "18. KayAiRetriever\n",
      "19. AmazonKendraRetriever\n",
      "20. KNNRetriever\n",
      "21. LlamaIndexGraphRetriever\n",
      "22. LlamaIndexRetriever\n",
      "23. MergerRetriever\n",
      "24. MetalRetriever\n",
      "25. MilvusRetriever\n",
      "26. MultiQueryRetriever\n",
      "27. MultiVectorRetriever\n",
      "28. OutlineRetriever\n",
      "29. ParentDocumentRetriever\n",
      "30. PineconeHybridSearchRetriever\n",
      "31. PubMedRetriever\n",
      "32. RePhraseQueryRetriever\n",
      "33. RemoteLangChainRetriever\n",
      "34. SelfQueryRetriever\n",
      "35. SVMRetriever\n",
      "36. TavilySearchAPIRetriever\n",
      "37. TFIDFRetriever\n",
      "38. TimeWeightedVectorStoreRetriever\n",
      "39. VespaRetriever\n",
      "40. WeaviateHybridSearchRetriever\n",
      "41. WebResearchRetriever\n",
      "42. WikipediaRetriever\n",
      "43. ZepRetriever\n",
      "44. ZillizRetriever \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma, FAISS\n",
    "faiss_vectorstore = FAISS.from_documents(split_docs, gpt_embeddings)\n",
    "inferenceQA(chat_model, faiss_vectorstore, questions = [\n",
    "        \"What is the class hierarchy?\",\n",
    "        \"What classes are derived from the Chain class?\",\n",
    "        \"What kind of retrievers does LangChain have?\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f6cac-e128-45ce-8516-cba36a2b4c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

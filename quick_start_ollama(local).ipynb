{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3075bc28-b9a2-495f-ad1a-168c1dd227d4",
   "metadata": {},
   "source": [
    "# Ollama Example in langchain\n",
    "This is a LLM example with a ollama local model.\n",
    "It's free and fast (I can easily run it on my GTX1660 Super)\n",
    "Code  \n",
    "https://python.langchain.com/docs/get_started/quickstart\n",
    "\n",
    "Ollama is a model manager, which allows you to download access models via Ollama\n",
    "\n",
    "Ollama Server  \n",
    "https://ollama.ai/download/linux  \n",
    "Ollama Model  \n",
    "https://ollama.ai/library  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780a4768-23c8-4e1c-a2a4-0ddc217c4869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id=\"llama2-uncensored\"\n",
    "# !ollama pull $model_id\n",
    "\n",
    "# NOTE: the model stores in ~/.ollama/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fa2840-a185-459c-9dc9-dd43283bacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c2256-08d7-40b2-b77e-38ea5e89ff5d",
   "metadata": {},
   "source": [
    "## Prompt (with model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a85460a-d845-4f9c-a664-d97c4b91f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a natural language processing (NLP) toolkit that provides various features for text analysis and language understanding. It offers several testing functions, including sentiment analysis, topic modeling, and named entity recognition, which can be useful in various applications such as customer feedback analysis, news article classification, and product recommendation systems. Additionally, Langsmith provides pre-trained models for various languages, which can be trained on large datasets to improve the accuracy of the NLP tasks performed by the toolkit.\n",
      "\n",
      "CPU times: user 161 ms, sys: 65.4 ms, total: 226 ms\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# llm.invoke(\"how can langsmith help with testing?\") <-- without streaming\n",
    "\n",
    "# streaming\n",
    "for chunk in llm.stream(\"how can langsmith help with testing?\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49156cd3-6d95-4c15-a49f-e838653c9314",
   "metadata": {},
   "source": [
    "## Prompt (with LCEL)\n",
    "\n",
    "Note that we pass an \"dict\" into invoke/stream/astream, not str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc604ae3-b331-4d8a-81de-29e77eac0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704bce43-d364-4c02-afab-7f12a5416e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are world class technical documentation writer.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))]) middle=[Ollama(model='llama2-uncensored')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf98a5e2-a56f-4a49-ad73-c4f0f2e121c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith provides a wide range of AI-powered tools to assist in the process of writing technical documents, such as automated document summarization, grammar checking, and error correction. These features can be extremely helpful for testing your technical documentation to ensure that it is clear, accurate, and free from errors before publishing or presenting it to clients.\n",
      "\n",
      "CPU times: user 92 ms, sys: 19.8 ms, total: 112 ms\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# no streaming\n",
    "# chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "\n",
    "## async streaming\n",
    "# async for chunk in chain.astream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "#     print(chunk, end=\"\", flush=True)\n",
    "\n",
    "# stream\n",
    "for chunk in chain.stream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6555af-3995-415b-9330-ef5907a6fd73",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45a5bafe-1351-475a-8ed3-f648bffe031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "{'source': 'https://blog.google/outreach-initiatives/sustainability/report-ai-sustainability-google-cop28/', 'title': 'New report from Google: AI and climate action', 'description': 'AI has the potential to mitigate 5-10% of global greenhouse gas emissions according to our new report with Boston Consulting Group.', 'language': 'en-us'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://blog.google/outreach-initiatives/sustainability/report-ai-sustainability-google-cop28/\")\n",
    "docs = loader.load()\n",
    "print(docs[0].__dict__.keys())\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc8162f-fc3e-487c-b009-bd2b18bc7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "all_text_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2bea7a7-e438-4add-af82-d485c7af8565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "gpt4all_embd = GPT4AllEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e6d6279-8a7b-4b51-b4d7-979e816929d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(all_text_splits, gpt4all_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b15eb0-e6b4-413d-80c7-d07197ff8921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Grow with Google\\n                  \\n                \\n\\n\\n\\n                  Sustainability\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Technology\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  AI\\n                  \\n                \\n\\n\\n\\n                  Developers\\n                  \\n                \\n\\n\\n\\n                  Families\\n                  \\n                \\n\\n\\n\\n                  Next billion users\\n                  \\n                \\n\\n\\n\\n                  Safety and security\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Inside Google\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Data centers and infrastructure\\n                  \\n                \\n\\n\\n\\n                  Doodles\\n                  \\n                \\n\\n\\n\\n                  Googlers\\n                  \\n                \\n\\n\\n\\n                  Life at Google', metadata={'source': 'https://blog.google/outreach-initiatives/sustainability/report-ai-sustainability-google-cop28/', 'title': 'New report from Google: AI and climate action', 'description': 'AI has the potential to mitigate 5-10% of global greenhouse gas emissions according to our new report with Boston Consulting Group.', 'language': 'en-us'})]\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1}) # default=4\n",
    "search= retriever.get_relevant_documents(\"google AI\")\n",
    "# == vectorstore.similarity_search(\"....\")\n",
    "print(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cecb604c-7343-4ca2-9ce4-a316e578e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "# from langchain.schema import format_document\n",
    "from langchain import PromptTemplate\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use five sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\")\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever, \n",
    "         \"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a20ad20-77dd-4f3b-bf33-d363df2c4036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AI can help optimize energy usage, reduce carbon footprints and improve the efficiency of renewable energy sources by predicting weather patterns more accurately and optimizing energy production schedules.\n",
      "2. AI algorithms can also assist in developing new green technologies such as sustainable materials and environmentally-friendly products by analyzing data on the impact of different manufacturing processes on the planet's ecosystem.\n",
      "3. AI can support climate action efforts by providing predictive insights into climate change patterns, allowing us to take preventative measures earlier rather than react later.\n",
      "4. The use of machine learning algorithms can also be used to predict and model the impacts of extreme weather events such as heat waves, floods or droughts, which are becoming more frequent due to climate change.\n",
      "5. Finally, AI-powered tools can help businesses reduce their carbon footprint by optimizing supply chains, reducing waste and improving resource efficiency.\n",
      "\n",
      "CPU times: user 299 ms, sys: 48.7 ms, total: 347 ms\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for chunk in rag_chain.stream(\"How can AI address climate challenges?\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc947cb-2b22-4cc3-a174-65751f5690ed",
   "metadata": {},
   "source": [
    "\n",
    "**Note**: If you want pass an `dict`, make sure the input layer is able to accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15723eea-4e83-4e76-94b3-3851c10c5b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) can help address climate challenges in several ways, including:\n",
      "1. Energy efficiency: AI can be used to optimize energy consumption in buildings and factories by analyzing data on energy usage patterns and identifying areas for improvement.\n",
      "2. Renewable energy production: AI can assist with the planning and operation of renewable energy systems, such as wind and solar farms, by optimizing their performance and reducing downtime.\n",
      "3. Carbon capture and storage: AI can help monitor and optimize carbon capture and storage (CCS) facilities to increase their efficiency and reduce costs.\n",
      "4. Climate modeling: AI can be used to improve climate models by analyzing large datasets and identifying patterns that may not be immediately apparent.\n",
      "5. Sustainable transportation: AI can assist with the development of more sustainable transportation systems, such as electric vehicles and public transit, by optimizing route planning and reducing traffic congestion. \n",
      "\n",
      "In summary, while AI cannot solve climate challenges on its own, it can be a powerful tool for addressing some of the most pressing issues facing our planet today.\n",
      "\n",
      "CPU times: user 342 ms, sys: 77.8 ms, total: 420 ms\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from operator import itemgetter\n",
    "rag_chain2 = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"q\") |retriever, \n",
    "         \"question\": itemgetter(\"q\")}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain2.stream({\"q\":\"How can AI address climate challenges?\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99100f4e-8b66-4610-a5ab-cd8d99cea796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# by default the Dockerfile specifies these versions: 3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX
# however for me to work i had to specify the exact version for my card ( 2060 ) it was 7.5
# https://developer.nvidia.com/cuda-gpus you can find the version for your card here
# TORCH_CUDA_ARCH_LIST=7.5

# these commands worked for me with roughly 4.5GB of vram
# CLI_ARGS= --listen --auto-devices --verbose --extensions gallery api google_translate webui_tavernai_charas  character_bias 
# EdgeGPT
# --model Llama-2-7b-chat-hf --load-in-8bit
# --model llama-7b-4bit --wbits 4  --settings settings.yaml --share

# the following examples have been tested with the files linked in docs/README_docker.md:
# example running 13b with 4bit/128 groupsize        : CLI_ARGS=--model llama-13b-4bit-128g --wbits 4 --listen --groupsize 128 --pre_layer 25
# example with loading api extension and public share: CLI_ARGS=--model llama-7b-4bit --wbits 4 --listen --auto-devices --no-stream --extensions api --share
# example running 7b with 8bit groupsize             : CLI_ARGS=--model llama-7b --load-in-8bit --listen --auto-devices
# WORKDIR_NAME=app
PROJECTDIR_NAME="project"
HOST_JUPYTER_PORT=7888
CONTAINER_JUPYTER_PORT=8888
HOST_MODEL_PATH="~/llama2/llama2_models/"
# HOST_MODEL_1 = "Llama-2-7b-chat-hf"
# HOST_MODEL_2 = "Llama-2-7b-Chat-GGUF"
# HOST_MODEL_3 = "Llama-2-7b-Chat-GPTQ"

# HOST_MODEL_4 = "Llama-2-13B-chat-GPTQ"
# HOST_MODEL_5 = "Llama-2-13b-chat-hf"
# HOST_MODEL_6 = "Llama2-Chinese-7b-Chat"
# HOST_MODEL_TRANS = "sentence-transformers"
HOST_LORA_PATH="~/llama2_loras/"
# HOST_LORA_1 = "Llama2-Chinese-7b-Chat-LoRA"

# # the port the webui binds to on the host
# HOST_PORT=7860
# # the port the webui binds to inside the container
# CONTAINER_PORT=7860

# # the port the api binds to on the host
# HOST_API_PORT=5000
# # the port the api binds to inside the container
# CONTAINER_API_PORT=5000

# # the port the api stream endpoint binds to on the host
# HOST_API_STREAM_PORT=5005
# # the port the api stream endpoint binds to inside the container
# CONTAINER_API_STREAM_PORT=5005

# # the version used to install text-generation-webui from
# WEBUI_VERSION=HEAD

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3075bc28-b9a2-495f-ad1a-168c1dd227d4",
   "metadata": {},
   "source": [
    "# Gemini Example in langchain\n",
    "This is a LLM example with Gemini of Google AI Studio.  \n",
    "https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb\n",
    "\n",
    "Google AI Studio  \n",
    "https://makersuite.google.com/  \n",
    "\n",
    "**Note**: Fill in the .env before start  \n",
    "you can get the key from https://makersuite.google.com/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780a4768-23c8-4e1c-a2a4-0ddc217c4869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet langchain-google-genai # This is Google AI Studio\n",
    "# !pip install --quiet langchain-google-vertexai # This is Vertex AI (GCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fa2840-a185-459c-9dc9-dd43283bacf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell and paste the API key in the prompt\n",
    "import os\n",
    "# import getpass\n",
    "\n",
    "# os.environ['GOOGLE_API_KEY'] = getpass.getpass('Gemini API Key:')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53693a-ee40-4385-9c0e-45c89caf1e02",
   "metadata": {},
   "source": [
    "API:\n",
    "https://api.python.langchain.com/en/latest/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html\n",
    "\n",
    "Add \"convert_system_message_to_human\" if there's any system role\n",
    ">SystemMessages are not yet supported!\n",
    ">\n",
    ">To automatically convert the leading SystemMessage to a HumanMessage,\n",
    ">set  `convert_system_message_to_human` to True. Example:\n",
    ">\n",
    ">llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f847b53-33c8-448d-a6a4-6b826b290da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google.generativeai.types.safety_types import HarmBlockThreshold, HarmCategory\n",
    "\n",
    "safety_settings = {\n",
    "    # Gemini blocks everything\n",
    "    # HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                                temperature=0.7, top_p=0.85, \n",
    "                                 safety_settings=safety_settings,\n",
    "                                convert_system_message_to_human=True) #SystemMessages are not yet supported!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c2256-08d7-40b2-b77e-38ea5e89ff5d",
   "metadata": {},
   "source": [
    "## Prompt (with model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a85460a-d845-4f9c-a664-d97c4b91f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Langsmith** is a powerful AI-powered code testing platform that can significantly enhance the testing process for developers. Here's how Langsmith can help with testing:\n",
      "\n",
      "**1. Automated Test Generation:**\n",
      "* Generates comprehensive test cases based on code coverage, reducing manual effort and ensuring thorough testing.\n",
      "* Supports various programming languages and frameworks, including Python, Java, JavaScript, and C++.\n",
      "\n",
      "**2. Smart Test Execution:**\n",
      "* Executes tests in parallel, optimizing testing time and resources.\n",
      "* Provides detailed test results with logs, screenshots, and videos for easy debugging and analysis.\n",
      "\n",
      "**3. Test Maintenance and Optimization:**\n",
      "* Automates regression testing by detecting changes in code and updating tests accordingly.\n",
      "* Identifies redundant or unnecessary tests, helping to streamline the testing process.\n",
      "\n",
      "**4. Cross-Platform Testing:**\n",
      "* Supports testing on multiple platforms, including web, mobile, and desktop, ensuring compatibility and seamless user experience.\n",
      "\n",
      "**5. Code Coverage Analysis:**\n",
      "* Provides detailed code coverage reports, highlighting areas that are not tested and suggesting additional test cases.\n",
      "* Helps identify untested code paths and ensures comprehensive testing.\n",
      "\n",
      "**6. Test Case Management:**\n",
      "* Organizes and manages test cases in a central repository, improving traceability and collaboration.\n",
      "* Allows for easy prioritization, assignment, and tracking of test cases.\n",
      "\n",
      "**7. Integration with CI/CD Pipelines:**\n",
      "* Integrates seamlessly with CI/CD pipelines, triggering automated testing as part of the build process.\n",
      "* Enables continuous testing and early detection of issues, improving software quality and release velocity.\n",
      "\n",
      "**8. AI-Powered Insights:**\n",
      "* Leverages AI to analyze test results and identify potential risks or areas for improvement.\n",
      "* Provides suggestions for optimizing test strategies and enhancing test coverage.\n",
      "\n",
      "**9. Collaboration and Reporting:**\n",
      "* Facilitates collaboration among team members, allowing for easy sharing and discussion of test results.\n",
      "* Generates detailed test reports that can be shared with stakeholders for transparency and compliance.\n",
      "\n",
      "By leveraging Langsmith's capabilities, developers can significantly improve the efficiency, accuracy, and coverage of their testing efforts, resulting in higher software quality and reduced time-to-market."
     ]
    }
   ],
   "source": [
    "# llm.invoke(\"how can langsmith help with testing?\") <-- without streaming\n",
    "\n",
    "# streaming\n",
    "async for chunk in llm.astream(\"how can langsmith help with testing?\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49156cd3-6d95-4c15-a49f-e838653c9314",
   "metadata": {},
   "source": [
    "## Prompt (with LCEL)\n",
    "\n",
    "Note that we pass an \"dict\" into invoke/stream/astream, not str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc604ae3-b331-4d8a-81de-29e77eac0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer. Please answer the answer in short\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a98ec12c-35b3-42d0-b61c-6b136421dc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith can help with testing by:\n",
      "- Generating test cases\n",
      "- Automating test execution\n",
      "- Analyzing test results"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm \n",
    "# print(chain)\n",
    "\n",
    "# chain.invoke({\"input\": \"how can langsmith help with testing?\"}) <-- without streaming\n",
    "async for chunk in chain.astream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26207258-d0f5-41a4-841f-0f7a35396f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith can help with testing by:\n",
      "\n",
      "- Generating test cases\n",
      "- Automating test execution\n",
      "- Reporting test results"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "# Note that the output will be string after StrOutputParser, not dict anymore\n",
    "\n",
    "# chain.invoke({\"input\": \"how can langsmith help with testing?\"}) <-- without streaming\n",
    "async for chunk in chain.astream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6475536d-e238-4f5a-acc2-70c59b530a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Automating testing processes\n",
      "- Generating test cases\n",
      "- Creating test plans\n",
      "- Executing tests\n",
      "- Analyzing results"
     ]
    }
   ],
   "source": [
    "# replace astream with stream\n",
    "for chunk in chain.stream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30bdda-c206-49a9-a02b-642599b163f0",
   "metadata": {},
   "source": [
    "## Data Loader and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b584eff1-6b4c-460a-9299-6b6164f61b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "{'source': 'https://blog.google/technology/ai/google-gemini-ai/#sundar-note', 'title': 'Introducing Gemini: Google’s most capable AI model yet', 'description': 'Gemini is our most capable and general model, built to be multimodal and optimized for three different sizes: Ultra, Pro and Nano.', 'language': 'en-us'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/#sundar-note\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].__dict__.keys())\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493cca6b-8975-4cfb-ba4a-470eb19852e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import format_document\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "# To query Gemini\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Write a concise summary of the following:\n",
    "    \"{text}\"\n",
    "    CONCISE SUMMARY:\"\"\")\n",
    "\n",
    "\n",
    "stuff_chain = (\n",
    "    # Extract data from the documents and add to the key `text`.\n",
    "    {\n",
    "        \"text\": lambda docs: \"\\n\\n\".join(\n",
    "                # format_document accept \"page_content\" and \"metadata\" in doc\n",
    "                format_document(doc, PromptTemplate.from_template(\"{page_content}\")) for doc in docs \n",
    "            )\n",
    "    }\n",
    "    | llm_prompt         # Prompt for Gemini\n",
    "    | llm                # Gemini function\n",
    "    | StrOutputParser()  # output parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3819efac-3d47-46a2-b267-677f4678852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google introduces Gemini, its most capable AI model yet, with state-of-the-art performance across benchmarks, next-generation capabilities, and optimized efficiency. Gemini 1.0, available in Ultra, Pro, and Nano sizes, excels in multimodal understanding, sophisticated reasoning, advanced coding, and reliability. Built with responsibility and safety in mind, Gemini incorporates comprehensive evaluations, safety classifiers, and external expert collaborations. Google products like Bard, Pixel, and Search will integrate Gemini, while developers and enterprise customers can access Gemini Pro via APIs. Gemini Ultra will undergo further trust and safety checks before broader availability, with Bard Advanced offering access to cutting-edge capabilities. Gemini represents a milestone in AI development, unlocking a future of innovation and transformative applications across various industries and domains."
     ]
    }
   ],
   "source": [
    "for chunk in stuff_chain.stream(docs):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25b496-7057-420a-9eaf-cf68ae0893d1",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7a4e3a-b0fc-45d8-a381-9055a0d37082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "{'source': 'https://blog.google/outreach-initiatives/sustainability/report-ai-sustainability-google-cop28/', 'title': 'New report from Google: AI and climate action', 'description': 'AI has the potential to mitigate 5-10% of global greenhouse gas emissions according to our new report with Boston Consulting Group.', 'language': 'en-us'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://blog.google/outreach-initiatives/sustainability/report-ai-sustainability-google-cop28/\")\n",
    "docs = loader.load()\n",
    "print(docs[0].__dict__.keys())\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ed59c9-7b6b-4321-b33e-94baf130d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Get text between \"...at COP28\" and \"POSTED IN:\"\n",
    "text_content = docs[0].page_content.split(\"Later this month at COP28\",1)[1].split(\"POSTED IN:\",1)[0]\n",
    "# We manually make doc, change source\n",
    "all_text_splits =  [Document(page_content=text_content, metadata={\"source\": \"local\"})]\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# all_text_splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5e30fac-93dd-4f49-a7b3-b64ec2b4993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb2aeeae-9dc2-4396-a1a6-f7ca98e75547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(all_text_splits, gemini_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83cc987b-9117-4642-bfd2-98dfef56c2e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\", global leaders will gather in Dubai to build momentum for climate action. The United Nations’ Intergovernmental Panel on Climate Change (IPCC) forecasts that the world needs to reduce emissions by 43% by 2030. We believe that artificial intelligence (AI) and collective action can help achieve this goal and create a sustainable future for everyone.Today, we released a report with Boston Consulting Group (BCG), which shows that AI has the potential to help mitigate 5-10% of global greenhouse gas (GHG) emissions by 2030 — the equivalent of the total annual emissions of the European Union. Here’s a look at how we’re building AI that can drive climate progress, while at the same time working to mitigate AI’s environmental impact.\\n\\n\\n\\n\\nAccelerating climate action with AIAI can have a transformative effect on climate progress. Already, it is starting to address climate challenges in three key areas: providing people and organizations with better information to make more sustainable choices, delivering improved predictions to help adapt to climate change, and finding recommendations to optimize climate action for high-impact applications.Here’s a look at how, at Google, we’ve used AI to address climate challenges:Providing helpful information: People are looking for information to reduce their environmental footprint. Fuel-efficient routing in Google Maps uses AI to suggest routes that have fewer hills, less traffic, and constant speeds with the same or similar ETA. Since launching in October 2021, fuel-efficient routing is estimated to have helped prevent more than 2.4 million metric tons of CO2e emissions — the equivalent of taking approximately 500,000 fuel-based cars off the road for a year.1Predicting climate-related events: Floods are the most common natural disaster, causing thousands of fatalities and\\u2009disrupting the lives of millions every year. Since 2018, Google Research has been working on our flood forecasting initiative, which uses advanced AI and geospatial analysis to provide real-time flooding information so communities and individuals can prepare for and respond to riverine floods. Our Flood Hub platform is available to more than 80 countries, providing forecasts up to seven days in advance for 460 million people.Optimizing climate action: Contrails — the thin, white lines you sometimes see behind airplanes — have a surprisingly large impact on our climate. The 2022 IPCC report noted that contrail clouds account for roughly 35% of aviation's global warming impact — which is over half the impact of the world’s jet fuel. Google Research teamed up with American Airlines and Breakthrough Energy to bring together huge amounts of data — like satellite imagery, weather and flight path data — and used AI to develop contrail forecast maps to test if pilots can choose routes that avoid creating contrails. After these test flights, we found that the pilots reduced contrails by 54%.\\n\\n\\n\\n\\nManaging the environmental impact of AIWhile scaling these applications of AI and finding new ways to use it to accelerate climate action is crucial, we need to build AI responsibly and manage the environmental impact associated with it.As AI is at an inflection point, predicting the future growth of energy use and emissions from AI compute in our data centers is challenging. Historically, data center energy consumption has grown much more slowly than demand for computing power. In 2022, global data center electricity consumption accounted for 1-1.3% of global final electricity demand.Making AI computing more efficient requires using proven methods to cut emissions, while also uncovering new ways to increase efficiency. To minimize the carbon footprint of AI workloads, we rely on tested practices that can reduce the energy required to train an AI model by up to 100 times and reduce associated emissions by up to 1,000 times. To support the next generation of AI advances, our Tensor Processing Units v4 is proven to be one of the fastest, most efficient and most sustainable ML infrastructure hubs in the world. Additionally, our data centers, where this AI computing takes place, are designed, built, and operated to maximize efficiency. A Google-owned and -operated data center is on average more than 1.5 times as energy efficient as a typical enterprise data center, and the average annual power usage effectiveness (PUE) for our global fleet of data centers was 1.10, compared with the industry average of 1.55.We take a climate-conscious approach to cooling our data centers, as we continue to champion responsible water use. Similar to a personal computer, data centers generate heat and must be cooled through air cooling, water cooling, refrigerants or some combination of these solutions. For our data centers, we aim to support hyperlocal factors and decisions, including hydrology, geography, energy and emissions factors. Water may be the most efficient means of cooling in many places and, when used responsibly, can play an important role in reducing emissions.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorking together to drive positive climate impactsCreating a sustainable future requires collective action from policymakers, government officials, city planners, business leaders and individuals. Policymakers, in particular, have a central role to play both in harnessing the potential of AI for climate action and in ensuring its sustainable and equitable use. Policymakers can make a difference in accelerating three outcomes:Enabling AI for climate progress by encouraging data sharing, ensuring affordable technology access, building awareness, and supporting the creation and expansion of AI and climate-related upskilling programs for corporations.Accelerating the deployment of AI for climate by defining public and private sector priorities, delivering on public sector use cases, and encouraging private sector action.Promoting environmentally and socially responsible deployment of AI.Together, we can boldly and responsibly develop more tools and products that harness the power of AI to accelerate the climate progress we need.\\n\\n\\n\\n\\n\", metadata={'source': 'local'})]\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1}) # default=4\n",
    "search= retriever.get_relevant_documents(\"google AI\")\n",
    "# == vectorstore.similarity_search(\"....\")\n",
    "print(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc7627b8-e199-4c5d-a707-a15b501ebe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use five sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\")\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs, \n",
    "         \"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53a924c3-b7c4-4a61-bcea-b8c06231e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI can address climate challenges by providing better information for sustainable choices, delivering improved predictions for adaptation, finding recommendations for high-impact climate action optimization, and managing the environmental impact associated with AI."
     ]
    }
   ],
   "source": [
    "# rag_chain.invoke(\"How can AI address climate challenges?\")\n",
    "for chunk in rag_chain.stream(\"How can AI address climate challenges?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d042b0-b205-4d67-9a15-0171b2cf2914",
   "metadata": {},
   "source": [
    "**Note**: If you want pass an `dict`, make sure the input layer is able to accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a04d6094-0d53-45e1-b22d-b4f46eb132da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI can address climate challenges by providing better information for sustainable choices, delivering improved predictions for climate change adaptation, and finding recommendations to optimize climate action. It can also help reduce greenhouse gas emissions by optimizing routing, predicting floods, and minimizing contrails. Additionally, AI can help make AI computing more efficient and reduce the carbon footprint of AI workloads.\n",
      "\n",
      "CPU times: user 30.7 ms, sys: 412 µs, total: 31.1 ms\n",
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from operator import itemgetter\n",
    "rag_chain2 = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"q\") |retriever, \n",
    "         \"question\": itemgetter(\"q\")}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain2.stream({\"q\":\"How can AI address climate challenges?\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74568c4a-5ce3-4b80-ab50-0cb7e72ee563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

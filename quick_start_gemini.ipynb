{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3075bc28-b9a2-495f-ad1a-168c1dd227d4",
   "metadata": {},
   "source": [
    "# Gemini Example in langchain\n",
    "This is a LLM example with Gemini of Google AI Studio.  \n",
    "https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb\n",
    "\n",
    "\n",
    "https://makersuite.google.com/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780a4768-23c8-4e1c-a2a4-0ddc217c4869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet langchain-google-genai # This is Google AI Studio\n",
    "# !pip install --quiet langchain-google-vertexai # This is Vertex AI (GCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fa2840-a185-459c-9dc9-dd43283bacf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Gemini API Key: ········\n"
     ]
    }
   ],
   "source": [
    "# Run this cell and paste the API key in the prompt\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = getpass.getpass('Gemini API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53693a-ee40-4385-9c0e-45c89caf1e02",
   "metadata": {},
   "source": [
    "API:\n",
    "https://api.python.langchain.com/en/latest/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html\n",
    "\n",
    "Add \"convert_system_message_to_human\" if there's any system role\n",
    ">SystemMessages are not yet supported!\n",
    ">\n",
    ">To automatically convert the leading SystemMessage to a HumanMessage,\n",
    ">set  `convert_system_message_to_human` to True. Example:\n",
    ">\n",
    ">llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f847b53-33c8-448d-a6a4-6b826b290da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google.generativeai.types.safety_types import HarmBlockThreshold, HarmCategory\n",
    "safety_settings = {\n",
    "    # HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE, \n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                                temperature=0.7, top_p=0.85, \n",
    "                                 safety_settings=safety_settings,\n",
    "                                convert_system_message_to_human=True) #SystemMessages are not yet supported!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c2256-08d7-40b2-b77e-38ea5e89ff5d",
   "metadata": {},
   "source": [
    "## Prompt (with model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a85460a-d845-4f9c-a664-d97c4b91f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith can help with testing in a number of ways:\n",
      "\n",
      "* **Automated testing:** Langsmith can automatically generate tests for your code. This can help you to identify bugs and ensure that your code is working as expected.\n",
      "* **Test coverage analysis:** Langsmith can analyze your tests to identify which parts of your code are not being tested. This can help you to improve your test coverage and ensure that your code is being tested thoroughly.\n",
      "* **Test case prioritization:** Langsmith can prioritize your test cases based on their importance. This can help you to focus your testing efforts on the most critical parts of your code.\n",
      "* **Test result analysis:** Langsmith can analyze your test results to identify which tests are failing. This can help you to quickly identify and fix bugs in your code.\n",
      "\n",
      "Langsmith is a powerful tool that can help you to improve the quality of your code. By using Langsmith, you can automate your testing, improve your test coverage, prioritize your test cases, and analyze your test results. This can help you to identify bugs early on, ensure that your code is working as expected, and improve the overall quality of your software."
     ]
    }
   ],
   "source": [
    "# llm.invoke(\"how can langsmith help with testing?\") <-- without streaming\n",
    "\n",
    "# streaming\n",
    "async for chunk in llm.astream(\"how can langsmith help with testing?\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49156cd3-6d95-4c15-a49f-e838653c9314",
   "metadata": {},
   "source": [
    "## Prompt (with LCEL)\n",
    "\n",
    "Note that we pass an \"dict\" into invoke/stream/astream, not str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc604ae3-b331-4d8a-81de-29e77eac0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer. Please answer the answer in short\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a98ec12c-35b3-42d0-b61c-6b136421dc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Automates test case creation and execution\n",
      "- Provides a central repository for test artifacts\n",
      "- Integrates with CI/CD pipelines\n",
      "- Facilitates collaboration among testers and developers"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm \n",
    "# print(chain)\n",
    "\n",
    "# chain.invoke({\"input\": \"how can langsmith help with testing?\"}) <-- without streaming\n",
    "async for chunk in chain.astream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26207258-d0f5-41a4-841f-0f7a35396f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Automate test case creation and execution\n",
      "- Generate test data and expected results\n",
      "- Provide test analytics and reporting\n",
      "- Integrate with testing tools and frameworks\n",
      "- Improve test efficiency and accuracy"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "# Note that the output will be string after StrOutputParser, not dict anymore\n",
    "\n",
    "# chain.invoke({\"input\": \"how can langsmith help with testing?\"}) <-- without streaming\n",
    "async for chunk in chain.astream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6475536d-e238-4f5a-acc2-70c59b530a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Automating test cases\n",
      "- Generating test data\n",
      "- Analyzing test results"
     ]
    }
   ],
   "source": [
    "# replace astream with stream\n",
    "for chunk in chain.stream({\"input\": \"how can langsmith help with testing?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30bdda-c206-49a9-a02b-642599b163f0",
   "metadata": {},
   "source": [
    "## Data Loader and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6417d9-ff0c-4340-a985-fcd51426af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b584eff1-6b4c-460a-9299-6b6164f61b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "{'source': 'https://blog.google/technology/ai/google-gemini-ai/#sundar-note', 'title': 'Introducing Gemini: Google’s most capable AI model yet', 'description': 'Gemini is our most capable and general model, built to be multimodal and optimized for three different sizes: Ultra, Pro and Nano.', 'language': 'en-us'}\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/#sundar-note\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].__dict__.keys())\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "493cca6b-8975-4cfb-ba4a-470eb19852e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import format_document\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "# To query Gemini\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Write a concise summary of the following:\n",
    "    \"{text}\"\n",
    "    CONCISE SUMMARY:\"\"\")\n",
    "\n",
    "\n",
    "stuff_chain = (\n",
    "    # Extract data from the documents and add to the key `text`.\n",
    "    {\n",
    "        \"text\": lambda docs: \"\\n\\n\".join(\n",
    "                # format_document accept \"page_content\" and \"metadata\" in doc\n",
    "                format_document(doc, PromptTemplate.from_template(\"{page_content}\")) for doc in docs \n",
    "            )\n",
    "    }\n",
    "    | llm_prompt         # Prompt for Gemini\n",
    "    | llm                # Gemini function\n",
    "    | StrOutputParser()  # output parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3819efac-3d47-46a2-b267-677f4678852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google introduces Gemini, its most capable AI model yet. Gemini surpasses state-of-the-art performance on various benchmarks, including multimodal tasks. It features advanced coding capabilities and sophisticated reasoning abilities. Gemini is scalable, efficient, and designed with responsibility and safety in mind. It will be available across Google products, including Bard, Pixel, Search, and Cloud services. Gemini represents a new era for Google, enabling a future of AI-powered innovation that enhances creativity, knowledge, and productivity."
     ]
    }
   ],
   "source": [
    "for chunk in stuff_chain.stream(docs):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25b496-7057-420a-9eaf-cf68ae0893d1",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be7a4e3a-b0fc-45d8-a381-9055a0d37082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "{'source': 'https://blog.google/outreach-initiatives/sustainability/report-ai-sustainability-google-cop28/', 'title': 'New report from Google: AI and climate action', 'description': 'AI has the potential to mitigate 5-10% of global greenhouse gas emissions according to our new report with Boston Consulting Group.', 'language': 'en-us'}\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://blog.google/outreach-initiatives/sustainability/report-ai-sustainability-google-cop28/\")\n",
    "docs = loader.load()\n",
    "print(docs[0].__dict__.keys())\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96ed59c9-7b6b-4321-b33e-94baf130d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text between \"...at COP28\" and \"POSTED IN:\"\n",
    "text_content = docs[0].page_content.split(\"Later this month at COP28\",1)[1].split(\"POSTED IN:\",1)[0]\n",
    "# We manually make doc, change source\n",
    "all_text_splits =  [Document(page_content=text_content, metadata={\"source\": \"local\"})]\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# all_text_splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5e30fac-93dd-4f49-a7b3-b64ec2b4993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb2aeeae-9dc2-4396-a1a6-f7ca98e75547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(all_text_splits, gemini_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83cc987b-9117-4642-bfd2-98dfef56c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\", global leaders will gather in Dubai to build momentum for climate action. The United Nations’ Intergovernmental Panel on Climate Change (IPCC) forecasts that the world needs to reduce emissions by 43% by 2030. We believe that artificial intelligence (AI) and collective action can help achieve this goal and create a sustainable future for everyone.Today, we released a report with Boston Consulting Group (BCG), which shows that AI has the potential to help mitigate 5-10% of global greenhouse gas (GHG) emissions by 2030 — the equivalent of the total annual emissions of the European Union. Here’s a look at how we’re building AI that can drive climate progress, while at the same time working to mitigate AI’s environmental impact.\\n\\n\\n\\n\\nAccelerating climate action with AIAI can have a transformative effect on climate progress. Already, it is starting to address climate challenges in three key areas: providing people and organizations with better information to make more sustainable choices, delivering improved predictions to help adapt to climate change, and finding recommendations to optimize climate action for high-impact applications.Here’s a look at how, at Google, we’ve used AI to address climate challenges:Providing helpful information: People are looking for information to reduce their environmental footprint. Fuel-efficient routing in Google Maps uses AI to suggest routes that have fewer hills, less traffic, and constant speeds with the same or similar ETA. Since launching in October 2021, fuel-efficient routing is estimated to have helped prevent more than 2.4 million metric tons of CO2e emissions — the equivalent of taking approximately 500,000 fuel-based cars off the road for a year.1Predicting climate-related events: Floods are the most common natural disaster, causing thousands of fatalities and\\u2009disrupting the lives of millions every year. Since 2018, Google Research has been working on our flood forecasting initiative, which uses advanced AI and geospatial analysis to provide real-time flooding information so communities and individuals can prepare for and respond to riverine floods. Our Flood Hub platform is available to more than 80 countries, providing forecasts up to seven days in advance for 460 million people.Optimizing climate action: Contrails — the thin, white lines you sometimes see behind airplanes — have a surprisingly large impact on our climate. The 2022 IPCC report noted that contrail clouds account for roughly 35% of aviation's global warming impact — which is over half the impact of the world’s jet fuel. Google Research teamed up with American Airlines and Breakthrough Energy to bring together huge amounts of data — like satellite imagery, weather and flight path data — and used AI to develop contrail forecast maps to test if pilots can choose routes that avoid creating contrails. After these test flights, we found that the pilots reduced contrails by 54%.\\n\\n\\n\\n\\nManaging the environmental impact of AIWhile scaling these applications of AI and finding new ways to use it to accelerate climate action is crucial, we need to build AI responsibly and manage the environmental impact associated with it.As AI is at an inflection point, predicting the future growth of energy use and emissions from AI compute in our data centers is challenging. Historically, data center energy consumption has grown much more slowly than demand for computing power. In 2022, global data center electricity consumption accounted for 1-1.3% of global final electricity demand.Making AI computing more efficient requires using proven methods to cut emissions, while also uncovering new ways to increase efficiency. To minimize the carbon footprint of AI workloads, we rely on tested practices that can reduce the energy required to train an AI model by up to 100 times and reduce associated emissions by up to 1,000 times. To support the next generation of AI advances, our Tensor Processing Units v4 is proven to be one of the fastest, most efficient and most sustainable ML infrastructure hubs in the world. Additionally, our data centers, where this AI computing takes place, are designed, built, and operated to maximize efficiency. A Google-owned and -operated data center is on average more than 1.5 times as energy efficient as a typical enterprise data center, and the average annual power usage effectiveness (PUE) for our global fleet of data centers was 1.10, compared with the industry average of 1.55.We take a climate-conscious approach to cooling our data centers, as we continue to champion responsible water use. Similar to a personal computer, data centers generate heat and must be cooled through air cooling, water cooling, refrigerants or some combination of these solutions. For our data centers, we aim to support hyperlocal factors and decisions, including hydrology, geography, energy and emissions factors. Water may be the most efficient means of cooling in many places and, when used responsibly, can play an important role in reducing emissions.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorking together to drive positive climate impactsCreating a sustainable future requires collective action from policymakers, government officials, city planners, business leaders and individuals. Policymakers, in particular, have a central role to play both in harnessing the potential of AI for climate action and in ensuring its sustainable and equitable use. Policymakers can make a difference in accelerating three outcomes:Enabling AI for climate progress by encouraging data sharing, ensuring affordable technology access, building awareness, and supporting the creation and expansion of AI and climate-related upskilling programs for corporations.Accelerating the deployment of AI for climate by defining public and private sector priorities, delivering on public sector use cases, and encouraging private sector action.Promoting environmentally and socially responsible deployment of AI.Together, we can boldly and responsibly develop more tools and products that harness the power of AI to accelerate the climate progress we need.\\n\\n\\n\\n\\n\", metadata={'source': 'local'})]\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1}) # default=4\n",
    "search= retriever.get_relevant_documents(\"google AI\")\n",
    "# == vectorstore.similarity_search(\"....\")\n",
    "print(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc7627b8-e199-4c5d-a707-a15b501ebe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use five sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\")\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs, \n",
    "         \"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a924c3-b7c4-4a61-bcea-b8c06231e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI can address climate challenges by providing better information for sustainable choices, delivering improved predictions for adaptation, and finding recommendations to optimize climate action. AI can also be used to manage the environmental impact of AI computing by using proven methods to cut emissions and uncover new ways to increase efficiency. By working together, policymakers, government officials, city planners, business leaders, and individuals can harness the potential of AI for climate action and ensure its sustainable and equitable use."
     ]
    }
   ],
   "source": [
    "# rag_chain.invoke(\"How can AI address climate challenges?\")\n",
    "for chunk in rag_chain.stream(\"How can AI address climate challenges?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2875fb-6ce9-4728-a790-64bc06a21a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
